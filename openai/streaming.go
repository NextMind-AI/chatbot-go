package openai

import (
	"context"
	"encoding/json"
	"fmt"
	"strings"
	"time"

	"github.com/NextMind-AI/chatbot-go/elevenlabs"
	"github.com/NextMind-AI/chatbot-go/redis"
	"github.com/NextMind-AI/chatbot-go/vonage"

	"github.com/openai/openai-go"
	"github.com/rs/zerolog/log"
)

// streamingConfig holds the configuration for a streaming chat completion request.
type streamingConfig struct {
	userID           string
	userName         string
	chatHistory      []redis.ChatMessage
	vonageClient     *vonage.Client
	redisClient      *redis.Client
	elevenLabsClient *elevenlabs.Client
	toNumber         string
}

// ProcessChatStreaming processes a chat conversation with streaming response.
// It sends messages to the user via WhatsApp as they are generated by the AI.
// This method does not use any tools.
func (c *Client) ProcessChatStreaming(
	ctx context.Context,
	userID string,
	userName string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		userName:         userName,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
	}
	return c.processStreamingChat(ctx, config)
}

// ProcessChatStreamingWithTools processes a chat conversation with the new two-step approach:
// First, it uses a sleep analyzer to determine wait time, then generates the actual response.
func (c *Client) ProcessChatStreamingWithTools(
	ctx context.Context,
	userID string,
	userName string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		userName:         userName,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
	}
	return c.ExecuteSleepAndRespond(ctx, config)
}

// processStreamingChat handles the core streaming logic.
// Since tools are no longer used, this simply converts history and streams the response.
func (c *Client) processStreamingChat(ctx context.Context, config streamingConfig) error {
	messages := c.convertChatHistoryWithUserName(config.chatHistory, config.userName, config.userID)
	return c.streamResponse(ctx, config, messages)
}

// streamResponse creates a streaming chat completion and sends messages via WhatsApp as they arrive.
// It handles the parsing of streamed JSON and manages message deduplication with guaranteed ordering.
func (c *Client) streamResponse(
	ctx context.Context,
	config streamingConfig,
	messages []openai.ChatCompletionMessageParamUnion,
) error {
	schemaParam := createSchemaParam()

	// Prepare tools for the request
	tools := []openai.ChatCompletionToolParam{}
	for _, tool := range c.tools {
		tools = append(tools, tool.Definition)
	}

	params := openai.ChatCompletionNewParams{
		Messages: messages,
		ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
			OfJSONSchema: &openai.ResponseFormatJSONSchemaParam{JSONSchema: schemaParam},
		},
		Model: c.model,
	}

	// Add tools if any are defined
	if len(tools) > 0 {
		params.Tools = tools
	}

	log.Info().
		Str("user_id", config.userID).
		Msg("Starting new streaming response")

	stream := c.client.Chat.Completions.NewStreaming(ctx, params)

	parser := NewStreamingJSONParser()
	var fullContent strings.Builder
	sentMessages := make(map[int]bool)

	messageQueue := make(chan messageWithIndex, 100)
	done := make(chan struct{})

	go func() {
		defer close(done)
		log.Info().
			Str("user_id", config.userID).
			Msg("Started goroutine for sequential message sending")
		c.sendMessagesSequentially(ctx, config, messageQueue)
		log.Info().
			Str("user_id", config.userID).
			Msg("Goroutine for sequential message sending finished")
	}()

	totalMessagesQueued := 0

	for stream.Next() {
		evt := stream.Current()
		log.Debug().
			Str("user_id", config.userID).
			Msg("Received new stream event")
		if len(evt.Choices) > 0 {
			content := evt.Choices[0].Delta.Content
			fullContent.WriteString(content)

			log.Debug().
				Str("user_id", config.userID).
				Str("content_chunk", content).
				Msg("Appended content chunk to fullContent")

			newMessages := parser.AddChunk(content)

			for i, msg := range newMessages {
				messageIndex := parser.MsgCount - len(newMessages) + i
				if !sentMessages[messageIndex] {
					sentMessages[messageIndex] = true
					totalMessagesQueued++

					log.Info().
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Int("total_queued", totalMessagesQueued).
						Str("content", msg.Content).
						Str("type", msg.Type).
						Msg("Queueing streamed message for sequential sending")

					select {
					case messageQueue <- messageWithIndex{
						message: msg,
						index:   messageIndex,
					}:
						log.Debug().
							Str("user_id", config.userID).
							Int("message_index", messageIndex).
							Msg("Message successfully sent to messageQueue")
					case <-ctx.Done():
						log.Warn().
							Str("user_id", config.userID).
							Int("total_queued", totalMessagesQueued).
							Msg("Context done while sending to messageQueue, closing queue")
						close(messageQueue)
						<-done
						return ctx.Err()
					}
				}
			}
		}
	}

	log.Info().
		Str("user_id", config.userID).
		Int("total_messages_queued", totalMessagesQueued).
		Msg("Stream finished, closing messageQueue")
	
	close(messageQueue)
	<-done

	if err := stream.Err(); err != nil {
		log.Error().
			Str("user_id", config.userID).
			Err(err).
			Msg("Stream encountered error")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Msg("Finalizing streaming response")
	return c.finalizeStreamingResponse(config.userID, fullContent.String(), config.redisClient)
}

// streamResponseWithoutTools streams the response without including tools in the streaming call
func (c *Client) streamResponseWithoutTools(
	ctx context.Context,
	config streamingConfig,
	messages []openai.ChatCompletionMessageParamUnion,
) error {
	schemaParam := createSchemaParam()

	log.Info().
		Str("user_id", config.userID).
		Msg("Starting new streaming response (without tools)")

	stream := c.client.Chat.Completions.NewStreaming(ctx, openai.ChatCompletionNewParams{
		Messages: messages,
		ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
			OfJSONSchema: &openai.ResponseFormatJSONSchemaParam{JSONSchema: schemaParam},
		},
		Model: c.model,
	})

	parser := NewStreamingJSONParser()
	var fullContent strings.Builder
	sentMessages := make(map[int]bool)

	messageQueue := make(chan messageWithIndex, 100)
	done := make(chan struct{})

	go func() {
		defer close(done)
		log.Info().
			Str("user_id", config.userID).
			Msg("Started goroutine for sequential message sending (without tools)")
		c.sendMessagesSequentially(ctx, config, messageQueue)
		log.Info().
			Str("user_id", config.userID).
			Msg("Goroutine for sequential message sending finished (without tools)")
	}()

	for stream.Next() {
		evt := stream.Current()
		log.Debug().
			Str("user_id", config.userID).
			Msg("Received new stream event (without tools)")
		if len(evt.Choices) > 0 {
			content := evt.Choices[0].Delta.Content
			fullContent.WriteString(content)

			log.Debug().
				Str("user_id", config.userID).
				Str("content_chunk", content).
				Msg("Appended content chunk to fullContent (without tools)")

			newMessages := parser.AddChunk(content)

			for i, msg := range newMessages {
				messageIndex := parser.MsgCount - len(newMessages) + i
				if !sentMessages[messageIndex] {
					sentMessages[messageIndex] = true

					log.Info().
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Str("content", msg.Content).
						Str("type", msg.Type).
						Msg("Queueing streamed message for sequential sending (without tools)")

					select {
					case messageQueue <- messageWithIndex{
						message: msg,
						index:   messageIndex,
					}:
						log.Debug().
							Str("user_id", config.userID).
							Int("message_index", messageIndex).
							Msg("Message sent to messageQueue (without tools)")
					case <-ctx.Done():
						log.Warn().
							Str("user_id", config.userID).
							Msg("Context done while sending to messageQueue (without tools), closing queue")
						close(messageQueue)
						<-done
						return ctx.Err()
					}
				}
			}
		}
	}

	log.Info().
		Str("user_id", config.userID).
		Msg("Stream finished, closing messageQueue (without tools)")
	close(messageQueue)
	<-done

	if err := stream.Err(); err != nil {
		log.Error().
			Str("user_id", config.userID).
			Err(err).
			Msg("Stream encountered error (without tools)")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Msg("Finalizing streaming response (without tools)")
	return c.finalizeStreamingResponse(config.userID, fullContent.String(), config.redisClient)
}

// handleToolCalls processes tool calls from the AI and returns updated messages
func (c *Client) handleToolCalls(
	ctx context.Context,
	messages []openai.ChatCompletionMessageParamUnion,
	userID string,
) ([]openai.ChatCompletionMessageParamUnion, error) {
	// Prepare tools for the request
	tools := []openai.ChatCompletionToolParam{}
	for _, tool := range c.tools {
		tools = append(tools, tool.Definition)
	}

	log.Info().
		Str("user_id", userID).
		Int("tool_count", len(tools)).
		Msg("Calling AI with custom tools")

	// Make initial chat completion request with tools
	completion, err := c.client.Chat.Completions.New(ctx, openai.ChatCompletionNewParams{
		Messages: messages,
		Tools:    tools,
		Model:    c.model,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to get completion with tools: %w", err)
	}

	// Check if there are any tool calls
	if len(completion.Choices) == 0 || len(completion.Choices[0].Message.ToolCalls) == 0 {
		log.Info().
			Str("user_id", userID).
			Msg("No tool calls made, proceeding with streaming")
		return messages, nil
	}

	// Add the assistant's message with tool calls to the conversation
	updatedMessages := append(messages, completion.Choices[0].Message.ToParam())

	// Process each tool call
	for _, toolCall := range completion.Choices[0].Message.ToolCalls {
		log.Info().
			Str("user_id", userID).
			Str("tool_name", toolCall.Function.Name).
			Str("tool_id", toolCall.ID).
			Msg("Processing tool call")

		// Find the tool handler
		var handler ToolHandler
		for _, tool := range c.tools {
			if tool.Definition.Function.Name == toolCall.Function.Name {
				handler = tool.Handler
				break
			}
		}

		if handler == nil {
			log.Error().
				Str("user_id", userID).
				Str("tool_name", toolCall.Function.Name).
				Msg("No handler found for tool")
			continue
		}

		// Parse tool arguments
		var args map[string]any
		err := json.Unmarshal([]byte(toolCall.Function.Arguments), &args)
		if err != nil {
			log.Error().
				Err(err).
				Str("user_id", userID).
				Str("tool_name", toolCall.Function.Name).
				Msg("Failed to parse tool arguments")
			continue
		}

		// Call the tool handler
		result, err := handler(ctx, args)
		if err != nil {
			log.Error().
				Err(err).
				Str("user_id", userID).
				Str("tool_name", toolCall.Function.Name).
				Msg("Tool handler returned error")
			result = fmt.Sprintf("Error: %s", err.Error())
		}

		log.Info().
			Str("user_id", userID).
			Str("tool_name", toolCall.Function.Name).
			Str("result", result).
			Msg("Tool call completed")

		// Add the tool result to the conversation
		updatedMessages = append(updatedMessages, openai.ToolMessage(result, toolCall.ID))
	}

	return updatedMessages, nil
}

// messageWithIndex wraps a message with its index for ordered processing
type messageWithIndex struct {
	message Message
	index   int
}

// sendMessagesSequentially processes messages from the queue one at a time to ensure ordering
func (c *Client) sendMessagesSequentially(
	ctx context.Context,
	config streamingConfig,
	messageQueue <-chan messageWithIndex,
) {
	isFirstMessage := true
	messagesProcessed := 0

	log.Info().
		Str("user_id", config.userID).
		Msg("Starting sequential message processing goroutine")

	defer func() {
		log.Info().
			Str("user_id", config.userID).
			Int("total_messages_processed", messagesProcessed).
			Msg("Sequential message processing goroutine finished")
	}()

	for {
		select {
		case msgWithIndex, ok := <-messageQueue:
			if !ok {
				log.Info().
					Str("user_id", config.userID).
					Int("messages_processed", messagesProcessed).
					Msg("Message queue closed, finishing sequential processing")
				return
			}

			msg := msgWithIndex.message
			messageIndex := msgWithIndex.index

			log.Info().
				Str("user_id", config.userID).
				Int("message_index", messageIndex).
				Int("messages_processed_so_far", messagesProcessed).
				Str("content", msg.Content).
				Str("type", msg.Type).
				Msg("Processing message from queue")

			if !isFirstMessage {
				log.Debug().
					Str("user_id", config.userID).
					Msg("Applying 500ms delay between messages")

				select {
				case <-time.After(500 * time.Millisecond):
				case <-ctx.Done():
					log.Info().
						Str("user_id", config.userID).
						Msg("Context cancelled during debounce delay")
					return
				}
			}
			isFirstMessage = false

			// Enviar a mensagem
			if msg.Type == "audio" {
				if err := c.sendAudioMessage(ctx, config, msg, messageIndex); err != nil {
					log.Error().
						Err(err).
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Msg("Failed to send audio message, continuing with next")
				} else {
					messagesProcessed++
				}
			} else {
				if err := c.sendTextMessage(ctx, config, msg, messageIndex); err != nil {
					log.Error().
						Err(err).
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Msg("Failed to send text message, continuing with next")
				} else {
					messagesProcessed++
				}
			}

		case <-ctx.Done():
			log.Info().
				Str("user_id", config.userID).
				Int("messages_processed", messagesProcessed).
				Msg("Context cancelled, stopping sequential message processing")
			return
		}
	}
}

// Funções auxiliares para melhor organização e logs
func (c *Client) sendAudioMessage(
	ctx context.Context,
	config streamingConfig,
	msg Message,
	messageIndex int,
) error {
	log.Info().
		Str("user_id", config.userID).
		Int("message_index", messageIndex).
		Str("content", msg.Content).
		Msg("Converting text to speech")

	audioURL, err := config.elevenLabsClient.ConvertTextToSpeechDefault(msg.Content)
	if err != nil {
		log.Error().
			Err(err).
			Str("user_id", config.userID).
			Str("content", msg.Content).
			Int("message_index", messageIndex).
			Msg("Error converting text to speech")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Int("message_index", messageIndex).
		Str("audio_url", audioURL).
		Msg("Sending audio message to Vonage")

	response, err := config.vonageClient.SendWhatsAppAudioMessage(
		config.toNumber,
		audioURL,
	)
	if err != nil {
		log.Error().
			Err(err).
			Str("user_id", config.userID).
			Str("to", config.toNumber).
			Str("audio_url", audioURL).
			Int("message_index", messageIndex).
			Msg("Error sending WhatsApp audio message to Vonage")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Str("message_uuid", response.MessageUUID).
		Str("audio_url", audioURL).
		Int("message_index", messageIndex).
		Msg("Successfully sent audio message via Vonage")

	return nil
}

func (c *Client) sendTextMessage(
	ctx context.Context,
	config streamingConfig,
	msg Message,
	messageIndex int,
) error {
	log.Info().
		Str("user_id", config.userID).
		Int("message_index", messageIndex).
		Str("content", msg.Content).
		Msg("Sending text message to Vonage")

	response, err := config.vonageClient.SendWhatsAppTextMessage(
		config.toNumber,
		msg.Content,
	)
	if err != nil {
		log.Error().
			Err(err).
			Str("user_id", config.userID).
			Str("to", config.toNumber).
			Str("content", msg.Content).
			Int("message_index", messageIndex).
			Msg("Error sending WhatsApp text message to Vonage")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Str("message_uuid", response.MessageUUID).
		Str("content", msg.Content).
		Int("message_index", messageIndex).
		Msg("Successfully sent text message via Vonage")

	return nil
}

// finalizeStreamingResponse validates the final JSON response and stores it in Redis.
// It ensures the complete response is properly formatted and saved for chat history.
func (c *Client) finalizeStreamingResponse(
	userID string,
	fullContent string,
	redisClient *redis.Client,
) error {
	log.Info().
		Str("user_id", userID).
		Int("content_length", len(fullContent)).
		Msg("Finalizing streaming response - validating JSON")

	var messageList MessageList
	if err := json.Unmarshal([]byte(fullContent), &messageList); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Str("content", fullContent).
			Msg("Error parsing final JSON response")
		return err
	}

	log.Info().
		Str("user_id", userID).
		Int("message_count", len(messageList.Messages)).
		Msg("Successfully parsed JSON response")

	allMessagesContent := []string{}
	for i, msg := range messageList.Messages {
		allMessagesContent = append(allMessagesContent, msg.Content)
		log.Debug().
			Str("user_id", userID).
			Int("message_index", i).
			Str("content", msg.Content).
			Str("type", msg.Type).
			Msg("Processing message for Redis storage")
	}
	fullResponse := strings.Join(allMessagesContent, "\n\n")

	log.Info().
		Str("user_id", userID).
		Int("final_response_length", len(fullResponse)).
		Msg("Storing bot message in Redis")

	if err := redisClient.AddBotMessage(userID, fullResponse); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Msg("Error storing bot message in Redis")
		return err
	}

	log.Info().
		Str("user_id", userID).
		Msg("Successfully stored bot message in Redis")

	return nil
}
