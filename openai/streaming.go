package openai

import (
	"chatbot/elevenlabs"
	"chatbot/redis"
	"chatbot/vonage"
	"context"
	"encoding/json"
	"strings"

	"github.com/openai/openai-go"
	"github.com/rs/zerolog/log"
)

// streamingConfig holds the configuration for a streaming chat completion request.
type streamingConfig struct {
	userID           string
	chatHistory      []redis.ChatMessage
	vonageClient     *vonage.Client
	redisClient      *redis.Client
	elevenLabsClient *elevenlabs.Client
	toNumber         string
	useTools         bool
}

// ProcessChatStreaming processes a chat conversation with streaming response.
// It sends messages to the user via WhatsApp as they are generated by the AI.
// This method does not use any tools.
func (c *Client) ProcessChatStreaming(
	ctx context.Context,
	userID string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
		useTools:         false,
	}
	return c.processStreamingChat(ctx, config)
}

// ProcessChatStreamingWithTools processes a chat conversation with streaming response and tool support.
// It handles tool calls if needed, then streams the response to the user via WhatsApp.
func (c *Client) ProcessChatStreamingWithTools(
	ctx context.Context,
	userID string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
		useTools:         true,
	}
	return c.processStreamingChat(ctx, config)
}

// ProcessChatStreamingWithoutTools processa chat streaming SEM ferramentas (usado no debounce)
func (c *Client) ProcessChatStreamingWithoutTools(
	ctx context.Context,
	userID string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	log.Info().
		Str("user_id", userID).
		Msg("Processando chat streaming SEM tools (debounce)")

	config := streamingConfig{
		userID:           userID,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
		useTools:         false, // SEM TOOLS para evitar duplicação
	}
	return c.processStreamingChat(ctx, config)
}

// processStreamingChat handles the core streaming logic for both tool and non-tool scenarios.
// It consolidates the common streaming functionality to avoid code duplication.
func (c *Client) processStreamingChat(ctx context.Context, config streamingConfig) error {
    messages := convertChatHistory(ctx, config.userID, config.chatHistory)

    if config.useTools {
        log.Info().Str("user_id", config.userID).Msg("Processando COM ferramentas")
        toolMessages, err := c.processToolsIfNeeded(ctx, config.userID, messages)
        if err != nil {
            return err
        }
        messages = toolMessages
    } else {
        log.Info().Str("user_id", config.userID).Msg("Processando SEM ferramentas (debounce)")
    }

    return c.streamResponse(ctx, config, messages)
}

// processToolsIfNeeded checks if tool calls are needed and processes them.
// Returns the updated messages after handling any tool calls.
func (c *Client) processToolsIfNeeded(
	ctx context.Context,
	userID string,
	messages []openai.ChatCompletionMessageParamUnion,
) ([]openai.ChatCompletionMessageParamUnion, error) {
	chatCompletion, err := c.createChatCompletionWithTools(ctx, messages)
	if err != nil {
		return messages, err
	}

	toolCalls := chatCompletion.Choices[0].Message.ToolCalls
	if len(toolCalls) > 0 {
		messages = append(messages, chatCompletion.Choices[0].Message.ToParam())

		// CORRIGIR: handleToolCalls retorna ([]messages, error), não ([]messages, bool)
		toolResponses, err := c.handleToolCalls(ctx, userID, toolCalls)
		if err != nil {
			return messages, err
		}

		messages = append(messages, toolResponses...)
	}

	return messages, nil
}

// streamResponse creates a streaming chat completion and sends messages via WhatsApp as they arrive.
// It handles the parsing of streamed JSON and manages message deduplication.
func (c *Client) streamResponse(
	ctx context.Context,
	config streamingConfig,
	messages []openai.ChatCompletionMessageParamUnion,
) error {
	schemaParam := createSchemaParam()

	stream := c.client.Chat.Completions.NewStreaming(ctx, openai.ChatCompletionNewParams{
		Messages: messages,
		ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
			OfJSONSchema: &openai.ResponseFormatJSONSchemaParam{JSONSchema: schemaParam},
		},
		Model: openai.ChatModelGPT4_1Mini,
	})

	parser := NewStreamingJSONParser()
	var fullContent strings.Builder
	sentMessages := make(map[int]bool)
	hasProcessedAnyMessage := false

	for stream.Next() {
		// Check if context was cancelled
		if ctx.Err() != nil {
			log.Info().
				Str("user_id", config.userID).
				Msg("Streaming cancelled due to context cancellation")
			return ctx.Err()
		}

		evt := stream.Current()
		if len(evt.Choices) > 0 {
			content := evt.Choices[0].Delta.Content
			fullContent.WriteString(content)

			newMessages := parser.AddChunk(content)

			for i, msg := range newMessages {
				messageIndex := parser.MsgCount - len(newMessages) + i
				if !sentMessages[messageIndex] {
					sentMessages[messageIndex] = true
					hasProcessedAnyMessage = true

					log.Info().
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Str("content", msg.Content).
						Str("type", msg.Type).
						Msg("Processing streamed message")

					if msg.Type == "audio" {
						audioURL, err := config.elevenLabsClient.ConvertTextToSpeechDefault(
							msg.Content,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("content", msg.Content).
								Msg("Error converting text to speech")
							continue
						}

						response, err := config.vonageClient.SendWhatsAppAudioMessage(
							config.toNumber,
							audioURL,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("to", config.toNumber).
								Str("audio_url", audioURL).
								Msg("Error sending WhatsApp audio message")
						} else {
							log.Info().
								Str("user_id", config.userID).
								Str("message_uuid", response.MessageUUID).
								Str("audio_url", audioURL).
								Msg("Sent audio message via Vonage")
						}
					} else {
						response, err := config.vonageClient.SendWhatsAppTextMessage(
							config.toNumber,
							msg.Content,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("to", config.toNumber).
								Str("content", msg.Content).
								Msg("Error sending WhatsApp text message")
						} else {
							log.Info().
								Str("user_id", config.userID).
								Str("message_uuid", response.MessageUUID).
								Str("content", msg.Content).
								Msg("Sent text message via Vonage")
						}
					}
				}
			}
		}
	}

	streamErr := stream.Err()
	if streamErr != nil {
		log.Error().
			Err(streamErr).
			Str("user_id", config.userID).
			Bool("processed_any_message", hasProcessedAnyMessage).
			Msg("Stream error occurred")

		// If we haven't processed any messages and there's a stream error,
		// this indicates a complete failure
		if !hasProcessedAnyMessage {
			return streamErr
		}
		// If we processed some messages but got an error, log it but don't fail completely
	}

	return c.finalizeStreamingResponse(config.userID, fullContent.String(), config.redisClient)
}

// finalizeStreamingResponse validates the final JSON response and stores it in Redis.
// It ensures the complete response is properly formatted and saved for chat history.
func (c *Client) finalizeStreamingResponse(
	userID string,
	fullContent string,
	redisClient *redis.Client,
) error {
	var messageList MessageList
	if err := json.Unmarshal([]byte(fullContent), &messageList); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Str("content", fullContent).
			Msg("Error parsing final JSON response")
		return err
	}

	allMessagesContent := []string{}
	for _, msg := range messageList.Messages {
		allMessagesContent = append(allMessagesContent, msg.Content)
	}
	fullResponse := strings.Join(allMessagesContent, "\n\n")

	if err := redisClient.AddBotMessage(userID, fullResponse); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Msg("Error storing bot message in Redis")
	}

	return nil
}
