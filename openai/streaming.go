package openai

import (
	"chatbot/elevenlabs"
	"chatbot/redis"
	"chatbot/vonage"
	"context"
	"encoding/json"
	"errors"
	"strings"

	"github.com/openai/openai-go"
	"github.com/rs/zerolog/log"
)

// streamingConfig holds the configuration for a streaming chat completion request.
type streamingConfig struct {
	userID           string
	chatHistory      []redis.ChatMessage
	vonageClient     *vonage.Client
	redisClient      *redis.Client
	elevenLabsClient *elevenlabs.Client
	toNumber         string
	useTools         bool
}

// ProcessChatStreaming processes a chat conversation with streaming response.
// It sends messages to the user via WhatsApp as they are generated by the AI.
// This method does not use any tools.
func (c *Client) ProcessChatStreaming(
	ctx context.Context,
	userID string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
		useTools:         false,
	}
	return c.processStreamingChat(ctx, config)
}

// ProcessChatStreamingWithTools processes a chat conversation with streaming response and tool support.
// It handles tool calls if needed, then streams the response to the user via WhatsApp.
func (c *Client) ProcessChatStreamingWithTools(
	ctx context.Context,
	userID string,
	chatHistory []redis.ChatMessage,
	vonageClient *vonage.Client,
	redisClient *redis.Client,
	elevenLabsClient *elevenlabs.Client,
	toNumber string,
) error {
	config := streamingConfig{
		userID:           userID,
		chatHistory:      chatHistory,
		vonageClient:     vonageClient,
		redisClient:      redisClient,
		elevenLabsClient: elevenLabsClient,
		toNumber:         toNumber,
		useTools:         true,
	}
	return c.processStreamingChat(ctx, config)
}

// processStreamingChat handles the core streaming logic for both tool and non-tool scenarios.
// It consolidates the common streaming functionality to avoid code duplication.
func (c *Client) processStreamingChat(ctx context.Context, config streamingConfig) error {
	messages := convertChatHistory(ctx, config.userID, config.chatHistory) // Passar ctx e userID

	if config.useTools {
		toolMessages, err := c.processToolsIfNeeded(ctx, config.userID, messages)
		if err != nil {
			return err
		}
		messages = toolMessages
	}

	return c.streamResponse(ctx, config, messages)
}

// processToolsIfNeeded checks if tool calls are needed and processes them.
// Returns the updated messages after handling any tool calls.
func (c *Client) processToolsIfNeeded(
	ctx context.Context,
	userID string,
	messages []openai.ChatCompletionMessageParamUnion,
) ([]openai.ChatCompletionMessageParamUnion, error) {
	chatCompletion, err := c.createChatCompletionWithTools(ctx, messages)
	if err != nil {
		return messages, err
	}

	toolCalls := chatCompletion.Choices[0].Message.ToolCalls
	if len(toolCalls) > 0 {
		messages = append(messages, chatCompletion.Choices[0].Message.ToParam())

		// CORRIGIR: handleToolCalls retorna ([]messages, error), nÃ£o ([]messages, bool)
		toolResponses, err := c.handleToolCalls(ctx, userID, toolCalls)
		if err != nil {
			return messages, err
		}

		messages = append(messages, toolResponses...)
	}

	return messages, nil
}

// streamResponse creates a streaming chat completion and sends messages via WhatsApp as they arrive.
// It handles the parsing of streamed JSON and manages message deduplication.
func (c *Client) streamResponse(
	ctx context.Context,
	config streamingConfig,
	messages []openai.ChatCompletionMessageParamUnion,
) error {
	schemaParam := createSchemaParam()

	// TEMP: Log schema param for debugging
	log.Info().
		Str("user_id", config.userID).
		Msg("DEBUG: Creating streaming request with JSON schema")

	stream := c.client.Chat.Completions.NewStreaming(ctx, openai.ChatCompletionNewParams{
		Messages: messages,
		ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
			OfJSONSchema: &openai.ResponseFormatJSONSchemaParam{JSONSchema: schemaParam},
		},
		Model: openai.ChatModelGPT4_1Mini,
	})

	parser := NewStreamingJSONParser()

	// TEMP: Log parser initialization
	log.Info().
		Str("user_id", config.userID).
		Msg("DEBUG: Initialized streaming JSON parser")

	var fullContent strings.Builder
	sentMessages := make(map[int]bool)
	hasProcessedAnyMessage := false
	var streamingError error

	// TEMP: Log before starting streaming loop
	log.Info().
		Str("user_id", config.userID).
		Msg("DEBUG: Starting streaming loop")

	for stream.Next() {
		// Check if context was cancelled
		if ctx.Err() != nil {
			log.Info().
				Str("user_id", config.userID).
				Msg("Streaming cancelled due to context cancellation")
			return ctx.Err()
		}

		evt := stream.Current()
		if len(evt.Choices) > 0 {
			content := evt.Choices[0].Delta.Content
			fullContent.WriteString(content)

			// TEMP: Use Info level to ensure logs appear in production
			log.Info().
				Str("user_id", config.userID).
				Str("raw_content", content).
				Int("content_length", len(content)).
				Msg("DEBUG: Received streaming content chunk")

			newMessages := parser.AddChunk(content)

			// TEMP: Use Info level to ensure logs appear in production
			log.Info().
				Str("user_id", config.userID).
				Int("new_messages_count", len(newMessages)).
				Int("total_msg_count", parser.MsgCount).
				Msg("DEBUG: Parser processed chunk")

			// TEMP: Use Info level to ensure logs appear in production
			if len(newMessages) == 0 {
				log.Info().
					Str("user_id", config.userID).
					Str("buffer_content", parser.GetBuffer()).
					Int("buffer_length", len(parser.GetBuffer())).
					Msg("DEBUG: No messages parsed from current chunk")
			}

			for i, msg := range newMessages {
				messageIndex := parser.MsgCount - len(newMessages) + i
				if !sentMessages[messageIndex] {
					sentMessages[messageIndex] = true
					hasProcessedAnyMessage = true

					log.Info().
						Str("user_id", config.userID).
						Int("message_index", messageIndex).
						Str("content", msg.Content).
						Str("type", msg.Type).
						Msg("Processing streamed message")

					if msg.Type == "audio" {
						audioURL, err := config.elevenLabsClient.ConvertTextToSpeechDefault(
							msg.Content,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("content", msg.Content).
								Msg("Error converting text to speech")
							continue
						}

						response, err := config.vonageClient.SendWhatsAppAudioMessage(
							config.toNumber,
							audioURL,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("to", config.toNumber).
								Str("audio_url", audioURL).
								Msg("Error sending WhatsApp audio message")
						} else {
							log.Info().
								Str("user_id", config.userID).
								Str("message_uuid", response.MessageUUID).
								Str("audio_url", audioURL).
								Msg("Sent audio message via Vonage")
						}
					} else {
						response, err := config.vonageClient.SendWhatsAppTextMessage(
							config.toNumber,
							msg.Content,
						)
						if err != nil {
							log.Error().
								Err(err).
								Str("user_id", config.userID).
								Str("to", config.toNumber).
								Str("content", msg.Content).
								Msg("Error sending WhatsApp text message")
						} else {
							log.Info().
								Str("user_id", config.userID).
								Str("message_uuid", response.MessageUUID).
								Str("content", msg.Content).
								Msg("Sent text message via Vonage")
						}
					}
				}
			}
		} else {
			// DEBUG: Log when no choices are available
			log.Debug().
				Str("user_id", config.userID).
				Msg("Stream event has no choices")
		}
	}

	streamErr := stream.Err()

	// TEMP: Use Info level to ensure logs appear in production
	log.Info().
		Str("user_id", config.userID).
		Bool("has_processed_any_message", hasProcessedAnyMessage).
		Int("full_content_length", fullContent.Len()).
		Str("full_content", fullContent.String()).
		Msg("DEBUG: Streaming loop completed")

	if streamErr != nil {
		log.Error().
			Err(streamErr).
			Str("user_id", config.userID).
			Bool("processed_any_message", hasProcessedAnyMessage).
			Msg("Stream error occurred")

		// CRITICAL FIX: Always store the streaming error for potential fallback
		streamingError = streamErr

		// If we haven't processed any messages and there's a stream error,
		// this indicates a complete failure
		if !hasProcessedAnyMessage {
			log.Error().
				Err(streamErr).
				Str("user_id", config.userID).
				Msg("Complete streaming failure - no messages were processed")
			return streamErr
		}
		// If we processed some messages but got an error, we still need to try finalization
		// but should return error if finalization also fails
		log.Warn().
			Err(streamErr).
			Str("user_id", config.userID).
			Msg("Partial streaming failure - attempting to finalize response")
	}

	// CRITICAL FIX: If no messages were processed during streaming, this is a problem
	// The response should not be considered successful if no messages were sent to the user
	if !hasProcessedAnyMessage && fullContent.Len() > 0 {
		contentSample := fullContent.String()
		if len(contentSample) > 200 {
			contentSample = contentSample[:200]
		}

		log.Error().
			Str("user_id", config.userID).
			Int("content_length", fullContent.Len()).
			Str("content_sample", contentSample).
			Msg("CRITICAL: Content received but no messages were processed - trying fallback parsing")

		// FALLBACK: Try to parse the complete JSON as a MessageList
		if err := c.tryFallbackParsing(config, fullContent.String()); err != nil {
			log.Error().
				Err(err).
				Str("user_id", config.userID).
				Msg("Fallback parsing also failed - returning error to trigger system fallback")

			// Return error to trigger fallback response
			return errors.New("streaming content received but no messages were parsed and sent")
		}

		// If fallback parsing succeeded, don't return an error
		log.Info().
			Str("user_id", config.userID).
			Msg("Fallback parsing succeeded - messages sent via WhatsApp")
	}

	// Try to finalize the streaming response
	finalizeErr := c.finalizeStreamingResponse(config.userID, fullContent.String(), config.redisClient)

	// CRITICAL FIX: If we had streaming errors AND finalization fails, return error
	// This ensures fallback is triggered when things go wrong
	if streamingError != nil && finalizeErr != nil {
		log.Error().
			Err(finalizeErr).
			Str("user_id", config.userID).
			Msg("Finalization failed after streaming error - returning error to trigger fallback")
		return finalizeErr
	}

	// If only finalization failed but streaming was OK, return finalization error
	if finalizeErr != nil {
		log.Error().
			Err(finalizeErr).
			Str("user_id", config.userID).
			Msg("Finalization failed - returning error to trigger fallback")
		return finalizeErr
	}

	// If we had streaming errors but finalization succeeded, log warning but don't fail
	// This allows partial responses to be completed
	if streamingError != nil {
		log.Warn().
			Err(streamingError).
			Str("user_id", config.userID).
			Msg("Streaming had errors but finalization succeeded - completing successfully")
	}

	return nil
}

// finalizeStreamingResponse validates the final JSON response and stores it in Redis.
// It ensures the complete response is properly formatted and saved for chat history.
func (c *Client) finalizeStreamingResponse(
	userID string,
	fullContent string,
	redisClient *redis.Client,
) error {
	// If we have no content, don't fail - this might be an empty response
	if strings.TrimSpace(fullContent) == "" {
		log.Warn().
			Str("user_id", userID).
			Msg("Empty content in finalization - skipping storage")
		return nil
	}

	var messageList MessageList
	if err := json.Unmarshal([]byte(fullContent), &messageList); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Str("content", fullContent).
			Msg("Error parsing final JSON response")

		// CRITICAL FIX: Instead of failing completely, try to extract any usable content
		// This prevents complete failures when partial responses were already sent
		fallbackContent := strings.TrimSpace(fullContent)

		// Try to extract content from malformed JSON by looking for content patterns
		if fallbackContent != "" {
			log.Warn().
				Str("user_id", userID).
				Msg("Using fallback content extraction due to JSON parse error")

			// Store the raw content as fallback
			if err := redisClient.AddBotMessage(userID, fallbackContent); err != nil {
				log.Error().
					Err(err).
					Str("user_id", userID).
					Msg("Error storing fallback message in Redis")
				return err
			}

			log.Info().
				Str("user_id", userID).
				Msg("Successfully stored fallback content in Redis")
			return nil
		}

		// If we can't extract any content, return the original error
		return err
	}

	// Normal processing for valid JSON
	allMessagesContent := []string{}
	for _, msg := range messageList.Messages {
		if strings.TrimSpace(msg.Content) != "" {
			allMessagesContent = append(allMessagesContent, msg.Content)
		}
	}

	if len(allMessagesContent) == 0 {
		log.Warn().
			Str("user_id", userID).
			Msg("No valid message content found in parsed JSON")
		return nil
	}

	fullResponse := strings.Join(allMessagesContent, "\n\n")

	if err := redisClient.AddBotMessage(userID, fullResponse); err != nil {
		log.Error().
			Err(err).
			Str("user_id", userID).
			Msg("Error storing bot message in Redis")
		return err
	}

	log.Info().
		Str("user_id", userID).
		Int("message_count", len(allMessagesContent)).
		Msg("Successfully stored complete response in Redis")

	return nil
}

// tryFallbackParsing attempts to parse the complete JSON response as a MessageList
// and send messages via WhatsApp when the streaming parser fails
func (c *Client) tryFallbackParsing(config streamingConfig, fullContent string) error {
	log.Info().
		Str("user_id", config.userID).
		Msg("Attempting fallback parsing of complete JSON response")

	var messageList MessageList
	if err := json.Unmarshal([]byte(fullContent), &messageList); err != nil {
		log.Error().
			Err(err).
			Str("user_id", config.userID).
			Str("content", fullContent).
			Msg("Failed to parse complete JSON as MessageList")
		return err
	}

	log.Info().
		Str("user_id", config.userID).
		Int("message_count", len(messageList.Messages)).
		Msg("Successfully parsed MessageList - sending messages via WhatsApp")

	// Send each message via WhatsApp
	for i, msg := range messageList.Messages {
		log.Info().
			Str("user_id", config.userID).
			Int("message_index", i).
			Str("content", msg.Content).
			Str("type", msg.Type).
			Msg("Sending fallback parsed message")

		if msg.Type == "audio" {
			audioURL, err := config.elevenLabsClient.ConvertTextToSpeechDefault(msg.Content)
			if err != nil {
				log.Error().
					Err(err).
					Str("user_id", config.userID).
					Str("content", msg.Content).
					Msg("Error converting text to speech in fallback")
				continue
			}

			response, err := config.vonageClient.SendWhatsAppAudioMessage(config.toNumber, audioURL)
			if err != nil {
				log.Error().
					Err(err).
					Str("user_id", config.userID).
					Str("to", config.toNumber).
					Str("audio_url", audioURL).
					Msg("Error sending WhatsApp audio message in fallback")
			} else {
				log.Info().
					Str("user_id", config.userID).
					Str("message_uuid", response.MessageUUID).
					Str("audio_url", audioURL).
					Msg("Sent fallback audio message via Vonage")
			}
		} else {
			response, err := config.vonageClient.SendWhatsAppTextMessage(config.toNumber, msg.Content)
			if err != nil {
				log.Error().
					Err(err).
					Str("user_id", config.userID).
					Str("to", config.toNumber).
					Str("content", msg.Content).
					Msg("Error sending WhatsApp text message in fallback")
			} else {
				log.Info().
					Str("user_id", config.userID).
					Str("message_uuid", response.MessageUUID).
					Str("content", msg.Content).
					Msg("Sent fallback text message via Vonage")
			}
		}
	}

	return nil
}
